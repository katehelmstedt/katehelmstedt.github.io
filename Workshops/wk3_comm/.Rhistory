library(dplyr)
library(purrr)
library(twitteR)
install.packages("twitteR")
library(twitteR)
load(url("http://varianceexplained.org/files/trump_tweets_df.rda"))
library(tidyr)
tweets <- trump_tweets_df %>%
select(id, statusSource, text, created) %>%
extract(statusSource, "source", "Twitter for (.*?)<") %>%
filter(source %in% c("iPhone", "Android"))
library(lubridate)
library(scales)
tweets %>%
count(source, hour = hour(with_tz(created, "EST"))) %>%
mutate(percent = n / sum(n)) %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
scale_y_continuous(labels = percent_format()) +
labs(x = "Hour of day (EST)",
y = "% of tweets",
color = "")
library(ggplot2)
tweets %>%
count(source, hour = hour(with_tz(created, "EST"))) %>%
mutate(percent = n / sum(n)) %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
scale_y_continuous(labels = percent_format()) +
labs(x = "Hour of day (EST)",
y = "% of tweets",
color = "")
tweet_picture_counts <- tweets %>%
filter(!str_detect(text, '^"')) %>%
count(source,
picture = ifelse(str_detect(text, "t.co"),
"Picture/link", "No picture/link"))
ggplot(tweet_picture_counts, aes(source, n, fill = picture)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "", y = "Number of tweets", fill = "")
tweet_picture_counts <- tweets %>%
filter(!str_detect(text, '^"')) %>%
count(source,
picture = ifelse(str_detect(text, "t.co"),
"Picture/link", "No picture/link"))
?str_detect
library(stringr)
tweet_picture_counts <- tweets %>%
filter(!str_detect(text, '^"')) %>%
count(source,
picture = ifelse(str_detect(text, "t.co"),
"Picture/link", "No picture/link"))
ggplot(tweet_picture_counts, aes(source, n, fill = picture)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "", y = "Number of tweets", fill = "")
library(tidytext)
reg <- "([^A-Za-z\\d#@']|'(?![A-Za-z\\d#@]))"
tweet_words <- tweets %>%
filter(!str_detect(text, '^"')) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|&amp;", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
tweet_words
library(tidytext)
install.packages("tidytext")
library(tidytext)
reg <- "([^A-Za-z\\d#@']|'(?![A-Za-z\\d#@]))"
tweet_words <- tweets %>%
filter(!str_detect(text, '^"')) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|&amp;", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
tweet_words
android_iphone_ratios <- tweet_words %>%
count(word, source) %>%
filter(sum(n) >= 5) %>%
spread(source, n, fill = 0) %>%
ungroup() %>%
mutate_each(funs((. + 1) / sum(. + 1)), -word) %>%
mutate(logratio = log2(Android / iPhone)) %>%
arrange(desc(logratio))
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
dplyr::select(word, sentiment)
nrc
sentiments
sentiments$word
get_sentiments(sentiments)
get_sentiments("sentiments")
get_sentiments("afinn")
install.packages("textdata")
library(textdata)
get_sentiments("afinn")
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
dplyr::select(word, sentiment)
get_sentiments("nrc")
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
dplyr::select(word, sentiment)
sentiments
nrc <- sentiments %>%
dplyr::select(word, sentiment)
nrc
get_sentiments("nrc")
sentiments
sentiments %>% inner_join(get_sentiments("nrc"))
sentiments %>% outer_join(get_sentiments("nrc"))
?inner_join
get_sentiments("nrc") %>% inner_join(sentiments)
get_sentiments("nrc") %>% inner_join(sentiments, by="word")
get_sentiments("nrc") %>% left_join(sentiments, by="word")
get_sentiments("nrc") %>% right_join(sentiments, by="word")
get_sentiments("nrc") %>% left_join(sentiments, by="word")
sentiments %>% right_join(get_sentiments("nrc") , by="word")
sentiments %>% semi_join(get_sentiments("nrc") , by="word")
nrc <- sentiments %>%
inner_join(get_sentiments("nrc")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "nrc")
nrc <- sentiments %>%
inner_join(get_sentiments("nrc")) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "nrc")
nrc <- sentiments %>%
inner_join(get_sentiments("nrc"))
nrc
nrc <- get_sentiments("nrc") %>%
inner_join(sentiments)
nrc
nrc <- get_sentiments("nrc") %>%
inner_join(sentiments, by='word')
nrc
nrc<-get_sentiments("nrc")
sources <- tweet_words %>%
group_by(source) %>%
mutate(total_words = n()) %>%
ungroup() %>%
distinct(id, source, total_words)
by_source_sentiment <- tweet_words %>%
inner_join(nrc, by = "word") %>%
count(sentiment, id) %>%
ungroup() %>%
complete(sentiment, id, fill = list(n = 0)) %>%
inner_join(sources) %>%
group_by(source, sentiment, total_words) %>%
summarize(words = sum(n)) %>%
ungroup()
head(by_source_sentiment)
?get_sentiments
library(broom)
sentiment_differences <- by_source_sentiment %>%
group_by(sentiment) %>%
do(tidy(poisson.test(.$words, .$total_words)))
sentiment_differences
?which.max
test <- 15:20
test
which.max(test)
names(test)
names(test)<-c("first", "second", "third", "fourth", "fifth", "sixth")
test
names(test)<-c("first", "second", "third", "fourth", "fifth", "kate")
test
which.max(test)
names(test)[which.max(test)  ]
names(test)[1]
names(test)[ which.max(test) ]
